# Criação de Pipeline de dados com Apache Airflow e PostgreSQL
 
from airflow import DAG
from datetime import datetime, timedelta
from airflow.providers.postgres.operators.postgres import PostgresOperator
 
### Agendador de movimentação dos dados:
### Uma vez por dia à meia-noite  0 0 * * *
 
with DAG('dag_pipeline',
    start_date = datetime(2022, 11, 10),
    schedule_interval='0 0 * * *',
    template_searchpath = '/opt/airflow/sql') as dag:
 
    task1 = PostgresOperator(
        task_id='criar_tabela_postgres',
        postgres_conn_id='postgres_airflow',
        sql='criar_tabela_postgres.sql'
       
    )
 
    task2 = PostgresOperator(
        task_id='criar_tabela_categoria',
        postgres_conn_id='postgres_airflow',
        sql='criar_tabela_categoria.sql'
       
    )
 
    task3 = PostgresOperator(
        task_id='inserir_dados_postgres',
        postgres_conn_id='postgres_airflow',
        sql='inserir_dados_postgres.sql'
    )
 
    task4 = PostgresOperator(
        task_id='inserir_dados_categoria',
        postgres_conn_id='postgres_airflow',
        sql='inserir_dados_categoria.sql'
    )
 
task1 >> task2 >> task3 >> task4

# Criação das tabelas e inserção de dados estão em SQL

### criar TB_Categoria
 
create table if not exists TB_Categoria (
                id INT generated by default as identity,
                name VARCHAR NOT NULL,
                dt date
            )
 
### criar TB_Funcionario
create table if not exists TB_Funcionario (
                id INT generated by default as identity,
                name VARCHAR NOT NULL,
                dt date
            )
 
### inserir dados TB_Categoria
insert into TB_Categoria (name, dt)
            values('Childrens wear', current_date)
 
### inserir dados TB_Funcionario
insert into TB_Funcionario (name, dt)
            values('Joan Callins', current_date)

